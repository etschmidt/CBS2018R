---
title: "Assignment 5"
output: 
    html_document: 
        number_sections: yes
        self_containted: yes
---

```{r settings,echo=FALSE}
knitr::opts_chunk$set(message=FALSE,cache=TRUE,error=TRUE)
```

# Estimate a Lasso model of FamilyIncome from the acs data at https://www.jaredlander.com/data/acs_ny.csv (Links to an external site.)Links to an external site. (use read.table to read the data since it works better for this file than read_csv). 
```{r}

library(magrittr)

library(glmnet)

income_data <- read.table(file='https://www.jaredlander.com/data/acs_ny.csv', header=TRUE, sep=',')
head(income_data)
```
## Use the cross-validated Lasso function (cv.glmnet) in the glmnetpackage, and the build.x and build.y functions in the useful package as shown in class. Do not include FoodStamp as a predictor. 

```{r}
incomeFormula <- FamilyIncome ~ Acres + FamilyType + NumBedrooms + NumChildren + NumPeople + NumUnits + NumVehicles + NumWorkers + OwnRent + YearBuilt + HouseCosts + ElectricBill + HeatingFuel + Insurance + Language - 1

incomeX_train <- build.x(incomeFormula, data=income_data, 
                      contrast=FALSE, sparse=TRUE)

incomeY_train <- build.y(incomeFormula, data=income_data)

income1 <- cv.glmnet(x=incomeX_train, y=incomeY_train, family='gaussian', nfolds=5)
```

## Plot the cross-validation curve and comment on what it represents. Plot the shrinkage path and comment on what this plot represents.
```{r}
library(coefplot)

coefpath(income1)
```

# For the above estimated model, which variables does Lasso select under lambda.min and lambda.1se? Present coeﬃcients for both models. Which one selects fewer variables and why? Show the coefplot for both values of lambda.
```{r}
library(coefplot)

coefplot(income1, sort='magnitude', lambda='lambda.1se')
```
```{r}
library(coefplot)

coefplot(income1, sort='magnitude', lambda='lambda.min')
```

## Present both the lambda values from the above estimated model. In your own words what do these parameters represent?
```{r}
library(coefplot)

income1$lambda.1se
```
```{r}
library(coefplot)

income1$lambda.min
```

# Estimate a Ridge model of the same dataset as before. 
```{r}
library(coefplot)

plot(income1)
```

## How do the coeﬃcients diﬀer from the lambda.1se coeﬃcients? Show them both numerically and as a coefficient plot.
```{r}
# I don't eknow what to do here
```

# Estimate a boosted tree model over the same data as before. Since this is for continuous data be sure to set appropriate objective and eval_metric arguments. Use a random portion of the data as a validation set for the watchlist. Also see which settings for max_depth, eta and nrounds work best based on validation error. 
```{r}
library(useful)
library(xgboost)

# create sample size of 20% for validation
# set.seed
samp.size = floor(0.8 * nrow(income_data))
train.ind <- sample(seq_len(nrow(income_data)), size = samp.size)
income_train = income_data[train.ind, ]
income_val = income_data[-train.ind, ]

incomeX_train = build.x(incomeFormula, data=income_train, contrasts=FALSE, sparse=TRUE)
incomeY_train = build.y(incomeFormula, data=income_train)

incomeX_val = build.x(incomeFormula, data=income_val, contrasts=FALSE, sparse=TRUE)
incomeY_val = build.y(incomeFormula, data=income_val)

xgTrain <- xgb.DMatrix(data=incomeX_train, label=incomeY_train) # holds x and y matrices

xgVal <- xgb.DMatrix(data=incomeX_val, label=incomeY_val)

incomeBoost <- xgb.train(
    data=xgTrain, 
    objective='reg:linear',
    nrounds=300,
    eval_metric='rmse',
    eta=0.1,
    watchlist=list(train=xgTrain, validate=xgVal), 
    early_stopping_rounds = 10
)

```

## Create a variable importance plot and comment on the top three predictors. Plot the training and validation loss (stored in the evaluation_log slot of the model) with dygraphs.
```{r}
library(useful)
library(xgboost)

xgb.plot.importance(xgb.importance(incomeBoost, feature_names=colnames(incomeX_train)), top_n = 3)
```

# Download the 2015 NFL Play-by-Play data from https://www.jaredlander.com/data/pbp-2015.csv (Links to an external site.)Links to an external site.
```{r}
play_data <- read.table(file='https://www.jaredlander.com/data/pbp-2015.csv', header=TRUE, sep=',')
head(play_data)
```
```{r}
names(play_data)
```

## Filter the data down to just one team and when PlayType is either ‘RUSH’ or ‘PASS’ and convert those to 0 and 1. Using a number of columns, create the appropriate X and Y matrices and xgb.DMatrix objects to fit an XGBoost model. Use a random portion of the data as a validation set for the watchlist. Be sure to set appropriate objective and eval_metric arguments and choose good max_depth, eta and nrounds settings. 
```{r}
library(dplyr)

# Get data
play_data <- play_data %>% 
    filter(OffenseTeam == "PHI") %>% 
    filter(PlayType %in% c('RUSH', 'PASS')) %>% 
    mutate(RorP = ifelse(PlayType == 'RUSH', 0, 1))
table(play_data$RorP) # 50% more likely to pass overall
```
```{r}
library(useful)
library(xgboost)

samp.size = floor(0.8 * nrow(play_data))
train.ind <- sample(seq_len(nrow(play_data)), size = samp.size)
play_train = play_data[train.ind, ]
play_val = play_data[-train.ind, ]

# make formula
playFormula <- RorP ~ Quarter + Minute + DefenseTeam + Down + ToGo + YardLine + SeriesFirstDown + SeasonYear + Formation

playX_train = build.x(playFormula, data=play_train, contrasts=FALSE, sparse=TRUE)
playY_train = build.y(playFormula, data=play_train)

playX_val = build.x(playFormula, data=play_val, contrasts=FALSE, sparse=TRUE)
playY_val = build.y(playFormula, data=play_val)

xgPlayTrain <- xgb.DMatrix(data=playX_train, label=playY_train) # holds x and y matrices

xgPlayVal <- xgb.DMatrix(data=playX_val, label=playY_val)

playBoost <- xgb.train(
    data=xgPlayTrain, 
    objective='binary:logistic',
    nrounds=300,
    eval_metric='rmse',
    eta=0.1,
    watchlist=list(train=xgPlayTrain, validate=xgPlayVal), 
    early_stopping_rounds = 10
)
```

## Plot variable importance and the training and validation loss.
```{r}
library(useful)
library(xgboost)

xgb.plot.importance(xgb.importance(playBoost, feature_names=colnames(playX_train)))
```
```{r}
library(dygraphs)

dygraph(playBoost$evaluation_log)
```
Bonus comic from SMBC:

![SMBC](https://www.smbc-comics.com/comics/1538492931-20181002.png)